---
title: CPU 并行加速和 GPU 并行加速初研究
---

并行计算在大规模计算中会起到很重要的加速作用。在绘制 Julia 集时需要创建和计算较大的矩阵（1000×1000），此时并行计算就很有作用。

常用的并行加速是通过多核 CPU 或多 CPU 创建多线程（或多进程）来实现的。具体的实现方法可以是 OPENMP 或 MPI，由于对这两种方法不是很熟悉，只是简单的使用过 OPENMP 中的预编译指令 `#pragma omp parallel for`。不过此方法很实用。GPU 并行加速是在 Nvidia 开发的 CUDA 平台上实现的。由于 GPU 上流处理器很多，所以其并行计算能力超过 CPU。以 Julia 集的绘制为例说明这两种并行加速方式。

## CPU 并行加速

采用 CPU 来绘制 Julia 集，需要使用循环 for 语句。绘制的 Julia 集的矩阵尺寸为 1000×1000，而且由于绘制一个像素点需要 4 个字节（分别代表 RGBA）。所以在此矩阵在内存中所占空间为 1000×1000×4Byte～4MB。每一个像素点的值由 Julia 的检测函数计算得到，检测函数根据像素点的位置判断该像素点是否属于 Julia 集，如果是得到的值为 1，否则为 0。

最具体的实现中，申请矩阵的内存，然后使用 2 次 for 循环来对矩阵进行复制。在每次 for 循环前加上 `#pragma omp parallel for`，即可实现简单的 CPU 并行加速。然后采用 OpenGL 来绘制位图。

{% highlight css %}
cl /EHsc –openmp file//进行并行计算
cl /EHsc file//不进行并行计算
{% endhighlight %}

## GPU 并行加速

利用 CUDA 来进行 GPU 加速，在 GPU 设备上申请矩阵所需存储空间（即在显存上申请存储空间），然后通过多个 Block 和多个 Thread 来计算矩阵各元素。然后将显存中的矩阵通过总线复制到内存上，最后是采用 OpenGL 绘制位图。

{% highlight css %}
nvcc –Xcomplier “\wd 4819” file –o file
{% endhighlight %}

## 结果分析

分别对不同的 Julia 规模进行计算，计算结果见表 1。GPU 的加速性能在较大规模时比 CPU 加速要强。当 Julia 规模较小时，由于存在显存和内存之间的数据传输，使得 GPU 并行计算时间比 CPU 并行计算时间要长。

<small>*表 1 计算结果*</small>

|Julia 规模|	不并行计算时间 /s|	CPU 并行计算时间 /s|	GPU 并行计算时间 /s|
| :------------: |:---------------:|:-----:|:-----:|
|100×100|	0.234|	0.031|	0.156|
|500×500|	5.616|	0.655|	0.328|
|1000×1000|	22.527|	2.234|	0.874|
|1024×1024|	23.961|	2.298|	0.89|

需要注意的是：

* 机器配置为 E5-2640 v2 2.0GHz ×2 CPU，64GB 1600MHz RAM，Quadro K4000。
* 计算时间具有一定的分散性，表中的值只代表某一次计算的时间，但多次计算的时间相差不大。
